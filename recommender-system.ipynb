{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!git init\n",
        "!touch .gitignore\n",
        "!echo \"info.env\" >> .gitignore\n",
        "!git check-ignore -v .env\n",
        "!pip install flask flask-cors pyngrok\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0LSBa-GcHBnG",
        "outputId": "8a09f3f8-139e-417e-d834-cbd18634481c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Reinitialized existing Git repository in /content/.git/\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (5.0.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup API for react app communication\n",
        "from flask import Flask, jsonify, request\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(\"info.env\")\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/data')\n",
        "def data():\n",
        "    return jsonify({\"message\": \"Working!\"})\n",
        "\n",
        "# Set up ngrok tunnel\n",
        "TOKEN = str(os.getenv(\"NGROK_TOKEN\"))\n",
        "ngrok.set_auth_token(TOKEN)\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4yUUsWNJOZF",
        "outputId": "1b5b9aef-3f3b-45f7-b421-b9367c3bab31"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://c81c-35-186-191-34.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h2K8BOdM2LFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iVHzVfik3Fha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjDadBzCFVx_",
        "outputId": "cc3d196d-36bc-4de8-fe9f-057f0e11701d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Project name  Project id  Difficulty average     UK    US  \\\n",
            "0           Mockingjay Coaster     7418434            2.666667   None  True   \n",
            "1                      Lei Bag     7422172            0.000000  False  True   \n",
            "2                       Ariana     1182504            4.656934   None  True   \n",
            "3                  Indivisible     7304441            4.276596   None  True   \n",
            "4  Mini Carrot Kawaii CuddlerÂ®     7420746            0.000000   None  True   \n",
            "5                 Gift Coaster     7386570            4.260870   None  True   \n",
            "6           Honeycomb Tank Top     7421964            3.000000   None  True   \n",
            "7                 Helios Ruana     7421147            0.000000   None  True   \n",
            "8           Agnes Sweater Vest     1305044            3.092105   None  True   \n",
            "9     Athabasca Falls Pullover     1279615            2.422222   None  True   \n",
            "\n",
            "   Yarn id Crochet gauge Knit gauge  Yarn name ply wpi  Min yardage  \\\n",
            "0       11          None         22         DK   8  11           30   \n",
            "1       11          None         22         DK   8  11          416   \n",
            "2       12          None         20    Worsted  10   9         1800   \n",
            "3       12          None         20    Worsted  10   9         2010   \n",
            "4       12          None         20    Worsted  10   9            0   \n",
            "5        5                       28  Fingering   4  14           60   \n",
            "6        1                       18       Aran  10   8          300   \n",
            "7       12          None         20    Worsted  10   9         1400   \n",
            "8       12          None         20    Worsted  10   9          110   \n",
            "9        1                       18       Aran  10   8          900   \n",
            "\n",
            "   Max yardage                                  Categories  \n",
            "0           40                             [Coaster, Home]  \n",
            "1          437                            [Messenger, Bag]  \n",
            "2         2800                         [Cardigan, Sweater]  \n",
            "3         2050  [Shrug / Bolero, Clothing, Throw, Blanket]  \n",
            "4            0                    [Food, Toys and Hobbies]  \n",
            "5           66                           [Potholder, Home]  \n",
            "6          900                      [Sleeveless Top, Tops]  \n",
            "7         2200                         [Cardigan, Sweater]  \n",
            "8          872                            [Vest, Clothing]  \n",
            "9         1850                         [Pullover, Sweater]  \n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import http.client\n",
        "import json\n",
        "import requests\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import re\n",
        "\n",
        "# Access credentials\n",
        "authUsername = os.getenv(\"API_USERNAME\")\n",
        "authPassword = os.getenv(\"API_PASSWORD\")\n",
        "\n",
        "### Pre-filtering based on inventory ###\n",
        "# Search based on specific filters\n",
        "page = 8\n",
        "page_size = 10\n",
        "craft = 'crochet'\n",
        "knit_gauge = 5\n",
        "weight = 'DK'\n",
        "query = 'dragon'\n",
        "\n",
        "# Define URL for the API request\n",
        "url = 'https://api.ravelry.com/patterns/search.json?page={}&page_size={}&craft={}'.format(page, page_size, craft)\n",
        "# Make request\n",
        "r = requests.get(url, auth=requests.auth.HTTPBasicAuth(authUsername, authPassword))\n",
        "# Close connection\n",
        "r.close()\n",
        "\n",
        "\n",
        "def getPatterns():\n",
        "  yarndf = pd.DataFrame()\n",
        "  keydf = pd.DataFrame()\n",
        "  if r.status_code == 200:\n",
        "      data = r.json()\n",
        "      # Extract pattern ID(s) from the search results\n",
        "      if 'patterns' in data and len(data['patterns']) > 0:\n",
        "        for i in range(len(data['patterns'])):\n",
        "            pattern_id = data['patterns'][i]['id']\n",
        "\n",
        "            # Define URL to get pattern details\n",
        "            pattern_url = f'https://api.ravelry.com/patterns/{pattern_id}.json'\n",
        "\n",
        "            # Make the request for pattern details\n",
        "            pattern_response = requests.get(pattern_url, auth=requests.auth.HTTPBasicAuth(authUsername, authPassword))\n",
        "            pattern_response.close()\n",
        "\n",
        "            # If patterns found, collect the necessary yarn info\n",
        "            if pattern_response.status_code == 200:\n",
        "                pattern_data = pattern_response.json()\n",
        "                try:\n",
        "                  #print(json.dumps(json.loads(pattern_response.text), indent=4))\n",
        "                  yarnData = pattern_data['pattern']['yarn_weight']\n",
        "                  #Extract the two main categories\n",
        "                  cats = pattern_data['pattern']['pattern_categories']\n",
        "                  categories = []\n",
        "                  for cat in cats:\n",
        "                    categories.append(cat['name'])\n",
        "                    categories.append(cat['parent']['name'])\n",
        "\n",
        "                  # Extract yardage for minimum/maximums\n",
        "                  yardage = ['0', '0']\n",
        "                  extracted = re.findall(r'\\d+', pattern_data['pattern']['yardage_description'])\n",
        "\n",
        "                  if len(extracted) == 2:\n",
        "                    yardage = extracted\n",
        "                  elif len(extracted) == 1:\n",
        "                    yardage[0] = extracted[0]\n",
        "                    yardage[1] = extracted[0]\n",
        "\n",
        "                  # Get project name and add all to dataframe\n",
        "                  yarndf = pd.concat([yarndf, pd.DataFrame([{'Project name': pattern_data['pattern']['name'],\n",
        "                                                            'Yarn id': yarnData['id'],\n",
        "                                                            'Crochet gauge': yarnData['crochet_gauge'],\n",
        "                                                            'Knit gauge': yarnData['knit_gauge'],\n",
        "                                                            'Yarn name': yarnData['name'],\n",
        "                                                            'ply': yarnData['ply'], 'wpi': yarnData['wpi'],\n",
        "                                                            'Min yardage': int(yardage[0]),\n",
        "                                                            'Max yardage': int(yardage[1]),\n",
        "                                                            'Categories': categories}])], ignore_index=True)\n",
        "\n",
        "                  # Get key information from pattern details for recommender\n",
        "                  keydf = pd.concat([keydf, pd.DataFrame([{'Project name': pattern_data['pattern']['name'],\n",
        "                                                          'Project id': pattern_data['pattern']['id'],\n",
        "                                                          'Difficulty average': pattern_data['pattern']['difficulty_average'],\n",
        "                                                          'UK': pattern_data['pattern']['has_uk_terminology'],\n",
        "                                                          'US' : pattern_data['pattern']['has_us_terminology']}])], ignore_index=True)\n",
        "                except:\n",
        "                  print(\"\")\n",
        "      else:\n",
        "        print(\"No patterns found\")\n",
        "  else:\n",
        "    print(\"Unable to access patterns\")\n",
        "\n",
        "  keydf = keydf.merge(yarndf, on='Project name')\n",
        "  print(keydf)\n",
        "  return keydf\n",
        "\n",
        "\n",
        "def fetchInventory():\n",
        "  # Open stored inventory into dataframe\n",
        "  with open(\"inventory.json\", \"r\") as file:\n",
        "    inventory = json.load(file)\n",
        "    inv = pd.DataFrame(inventory)\n",
        "    groupedInv = inv.groupby(['Yarn name','ply', 'wpi', 'Total yardage']).agg(\n",
        "        min_yardage=('Total yardage', 'min'),\n",
        "        max_yardage=('Total yardage', 'max')).reset_index()\n",
        "\n",
        "    print(groupedInv)\n",
        "    return groupedInv\n",
        "\n",
        "def filterPatterns(groupedInv, patterns):\n",
        "  # Filters patterns for yarn available in inventory\n",
        "  filtereddf = patterns[patterns['Yarn name'].isin(groupedInv['Yarn name'])]\n",
        "  finaldf = pd.DataFrame(columns = patterns.columns)\n",
        "  for idx, row in filtereddf.iterrows():\n",
        "    rowYardage = row['Max yardage']\n",
        "    maxYardage = int(max(groupedInv.loc[groupedInv['Yarn name'] == row['Yarn name'], 'max_yardage'].values))\n",
        "\n",
        "    if (rowYardage > 0) & (rowYardage <= maxYardage):\n",
        "      # Directly adds if empty for future compatibility\n",
        "      if finaldf.empty:\n",
        "        finaldf = pd.DataFrame([row])\n",
        "      else:\n",
        "        finaldf = pd.concat([finaldf, pd.DataFrame([row])], ignore_index = True)\n",
        "\n",
        "  print(finaldf)\n",
        "\n",
        "patterns = getPatterns()\n",
        "\n",
        "@app.route('/fetchpatterns', methods=['GET'])\n",
        "def fetch_patterns():\n",
        "    print(\"/patterns route was hit\")\n",
        "    patterns = getPatterns()\n",
        "    return jsonify(patterns.to_dict(orient='records'))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text pre-processing before recommender\n",
        "chars = r'[^\\w\\s]' # Code for removing special characters\n",
        "patterns['Project name'] = patterns['Project name'].replace(chars, '', regex=True)\n",
        "\n",
        "# Get current yarn inventory and filter through patterns\n",
        "groupedInv = fetchInventory()\n",
        "filterPatterns(groupedInv, patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yguGHnCiWGV3",
        "outputId": "cc64e4aa-18c1-4965-fa8d-ea88833903da"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Yarn name  ply  wpi  Total yardage  min_yardage  max_yardage\n",
            "0         DK    8   11            500          500          500\n",
            "1         DK    8   12            200          200          200\n",
            "2  Fingering    4   14            800          800          800\n",
            "         Project name  Project id  Difficulty average     UK    US  Yarn id  \\\n",
            "0  Mockingjay Coaster     7418434            2.666667   None  True       11   \n",
            "1             Lei Bag     7422172            0.000000  False  True       11   \n",
            "2        Gift Coaster     7386570            4.260870   None  True        5   \n",
            "\n",
            "  Crochet gauge Knit gauge  Yarn name ply wpi  Min yardage  Max yardage  \\\n",
            "0          None         22         DK   8  11           30           40   \n",
            "1          None         22         DK   8  11          416          437   \n",
            "2                       28  Fingering   4  14           60           66   \n",
            "\n",
            "          Categories  \n",
            "0    [Coaster, Home]  \n",
            "1   [Messenger, Bag]  \n",
            "2  [Potholder, Home]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpapB8EaJjYm",
        "outputId": "91b14e20-c89d-4b46-b731-7a24814f8b96"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Basic recommender ###\n",
        "# Take the last 5 patterns saved by the user and use the average calculated metrics to then recommend\n",
        "# In release, should use the saved and completed patterns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Gets patterns users have saved/started making\n",
        "def readSaved():\n",
        "  with open(\"saved.json\", \"r\") as file:\n",
        "    savedPatterns = json.load(file)\n",
        "    saved = pd.DataFrame(savedPatterns)\n",
        "    return saved\n",
        "\n",
        "# Vectorizes features\n",
        "def vectorize(names, bow, vectorizer):\n",
        "  tfidfTransformer = TfidfTransformer()\n",
        "  tfidfMatrix = tfidfTransformer.fit_transform(bow)\n",
        "  return pd.DataFrame(tfidfMatrix.toarray())\n",
        "\n",
        "# Takes features of saved patterns and finds the similairty against other found patterns\n",
        "def transformPatterns(saved, patterns):\n",
        "  savedNames = saved['Project name'].tolist()\n",
        "  patternNames = patterns['Project name'].tolist()\n",
        "  #Features to be used for comparing patterns\n",
        "  features = ['Project name', 'Difficulty average', 'US', 'UK', \"Categories\"]\n",
        "\n",
        "  savedCombined = saved.copy()\n",
        "  patternsCombined = patterns.copy()\n",
        "\n",
        "  # Features used for comparing patterns\n",
        "  def combineFeatures(data):\n",
        "    return data['Project name'] + ' ' + str(data['Difficulty average']) + ' ' + str(data['US']) + ' ' + str(data['UK']) + ' ' + str(data['Categories'][0]) + ' ' + str(data[\"Categories\"][1])\n",
        "\n",
        "  # Fills in any missing data\n",
        "  for feature in features:\n",
        "    savedCombined[feature] = savedCombined[feature].fillna('')\n",
        "    patternsCombined[feature] = patternsCombined[feature].fillna('')\n",
        "\n",
        "  savedCombined['combinedFeatures'] = savedCombined.apply(combineFeatures, axis=1)\n",
        "  patternsCombined['combinedFeatures'] = patternsCombined.apply(combineFeatures, axis=1)\n",
        "  # Combines all words so features from saved and patterns are used in the vectorising process\n",
        "  allCombined = pd.concat([savedCombined[\"combinedFeatures\"], patternsCombined[\"combinedFeatures\"]])\n",
        "\n",
        "  vectorizer = CountVectorizer()\n",
        "  bagOfWordsMatrix = vectorizer.fit_transform(allCombined)\n",
        "\n",
        "  # Splits the combined vectorizing to compare\n",
        "  savedMatrix = vectorize(savedNames, bagOfWordsMatrix[:len(saved)], vectorizer)\n",
        "  patternMatrix = vectorize(patternNames, bagOfWordsMatrix[len(saved):], vectorizer)\n",
        "\n",
        "  # Finds similaritys\n",
        "  similar = cosine_similarity(patternMatrix, savedMatrix)\n",
        "  similarDf = pd.DataFrame(similar, index = patternNames, columns = savedNames)\n",
        "  # Totals similarity across all saved patterns to find the best overall recommended ones\n",
        "  totals = pd.DataFrame(similarDf.sum(axis=1))\n",
        "  totals.sort_values(by=[0], ascending=False, inplace=True)\n",
        "  # Displays top 10 recommended patterns\n",
        "  print(totals.head(10))\n",
        "\n",
        "saved = readSaved()\n",
        "transformPatterns(saved, patterns)\n"
      ],
      "metadata": {
        "id": "i4fUQJH1WX5R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "55280b7d-92aa-4a0f-a51d-18c99dd27699"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Categories'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Categories'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0c7dd73d44ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0msaved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadSaved\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtransformPatterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-0c7dd73d44ee>\u001b[0m in \u001b[0;36mtransformPatterns\u001b[0;34m(saved, patterns)\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;31m# Fills in any missing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0msavedCombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msavedCombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mpatternsCombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatternsCombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Categories'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes for retrieving names for the recommender\n",
        "*   Remove any symbols from pattern names cause having \" causes issues with the json\n",
        "*   Any missing data should be 0 or none\n",
        "* Probably include links to the projects when saving to the json\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0hgPoHkKsrUK"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}